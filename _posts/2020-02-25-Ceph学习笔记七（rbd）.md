## Ceph学习笔记七（rbd）.md
Ceph可以同时提供对象存储RADOSGW、块存储RBD、文件系统存储Ceph FS。 RBD即RADOS Block Device的简称，RBD块存储是最稳定且最常用的存储类型。RBD块设备类似磁盘可以被挂载。 RBD块设备具有快照、多副本、克隆和一致性等特性，数据以条带化的方式存储在Ceph集群的多个OSD中。  
块是一个有序字节，普通的块大小为512字节。基于块的存储是最常见的存储方式，例如硬盘。  
客户端访问RBD有两种方式:

    通过内核模块rbd.ko将镜像映射为本地块设备，通常设置文件一般为：/dev/rbd*
    另一种是通过librbd接口，KVM虚拟机就是使用这种接口。 
#### rbd命令使用：
RBD的使用实际上就是对RBD image的使用，RBD image是由多个对象条带化存储到后端的块设备。  
- 创建块设备镜像  
  ``` bash
  #rbd create --size {megabytes} {pool-name}/{image-name}
  如果pool_name不指定，则默认的pool是rbd。 下面的命令将创建一个10GB大小的块设备
  #rbd create --size=10240 foo_image
  ```

- 调整镜像的大小：
  ``` bash
  rbd resize <pool name>/<image name> --size <size numbe>
  ```
  **使用resize就可以调整镜像的大小，一般建议只增不减，如果是减少的话需要加一个选项--allow-shrink**

- 查看块设备镜像  
  ``` bash
  #rbd info {pool-name}/{image-name}
  ```
- 将设备映像到系统内核：
  该命令会在系统中映射一个/dev/rbd* 的设备，可以通过mount挂载
  ``` bash
  rbd map {image-name} --pool {pool-name}
  rbd info foo_image
  rbd image 'foo_image':
        size 10240 MB in 2560 objects
        order 22 (4096 kB objects)
        block_name_prefix: rbd_data.1218c2ae8944a
        format: 2
        features: layering, exclusive-lock, object-map, fast-diff, deep-flatten
        flags:


  rbd feature disable foo_image exclusive-lock, object-map, fast-diff, deep-flatten --pool rbd
  ```
  注意到上面的rbd info显示的RBD镜像的format为2，Format 2的RBD镜像支持RBD分层，是实现Copy-On-Write的前提条件。  
  格式化块设备镜像  
  #mkfs.ext4 /dev/rbd0  

- 取消块设备和内核映射
  ``` bash
  #rbd unmap foo_image --pool rbd
  ```
- 删除块设备镜像
  ``` bash
  #rbd rm {pool-name}/{image-name}
  #rbd rm rbd/foo_image
  ```
  通常不推荐直接删除镜像，这种方法删除镜像后，镜像将不可恢复。推荐使用trash命令，这个命令删除是将镜像移动一回收站，如果想找回还可以恢复，如
  ``` bash
  #rbd trash move <pool name>/<image name>
  #rbd trash list --pool <pool name>
  #rbd trash restore <pool name>/<id>
  ```
  trash move代表将镜像移动到回收站，还可以使用list查看回收站所有镜像、remove从回收站删除镜像，restore从回收站恢复、purge清空回收站。使用trash在操作的时候同样需要指定--pool，也可以使用spec格式，在restore的时候可以指定镜像的ID，在list的时候可以显示出镜像的ID。


- 创建快照
  ``` bash
  #rbd create --size 10240 foo_image
  #rbd snap create foo_image@foo_snap
  ```
- 列出创建的快照
  ``` bash
  rbd snap list rbd/foo_image
  SNAPID NAME         SIZE
     4 foo_snap 10240 MB
  或者使用rbd ls {pool-name} -l
  #rbd ls rbd -l 
  查看快照的详细信息：
  #rbd info rbd/foo_image@foo_snap
  rbd image 'foo_image':
        size 10240 MB in 2560 objects
        order 22 (4096 kB objects)
        block_name_prefix: rbd_data.121b62ae8944a
        format: 2
        features: layering, exclusive-lock, object-map, fast-diff, deep-flatten
        flags:
        protected: False
  ```
  ``` text
    size：镜像的大小与被分割成的条带数。
    order 22：条带的编号，有效范围是12到25，对应4K到32M，而22代表2的22次方，这样刚好是4M。
    id：镜像的ID标识。
    block_name_prefix：名称前缀。
    format：使用的镜像格式，默认为2。
    features：当前镜像的功能特性。
    op_features：可选的功能特性。
  ```

- 回滚快照
  ``` bash
  回滚镜像到指定快照
  #rbd snap rollback <pool name>/<image name>@<snap name>
  ```
  **注意： 在回滚快照之需要将镜像取消镜像的映射，然后再回滚**

- 限制快照数
  ``` bash
  #rbd snap limit set <pool name>/<image name> --limit 3
  取消限制
  #rbd snap limit clear <pool name>/<image name>
  ```

- 克隆快照
  快照必须处于被保护状态才能被克隆
  ``` bash
  设置快照为保护状态
  #rbd snap protect rbd/foo_image@foo_snap
  查看快照状态
  #rbd info rbd/foo_image@foo_snap
  rbd image 'foo_image':
        size 10240 MB in 2560 objects
        order 22 (4096 kB objects)
        block_name_prefix: rbd_data.121b62ae8944a
        format: 2
        features: layering, exclusive-lock, object-map, fast-diff, deep-flatten
        flags:
        protected: True

  克隆快照到另一个RBD pool的新image
  #rbd clone {pool-name}/{parent-image}@{snap-name} {pool-name}/{child-image-name}
  #rbd clone rbd/foo_image@foo_snap kube/bar_image

  查看克隆的镜像
  #rbd ls kube -l
  NAME          SIZE PARENT                 FMT PROT LOCK
  bar_image   10240M rbd/foo_image@foo_snap   2

  前面提到过format为2的image支持分层，接下来我们看一下foo_image@foo_snap这个快照的children：
  #rbd children {pool-name}/{image-name}@{snapshot-name}
  #rbd children rbd/foo_image@foo_snap
  kube/bar_image

- 快照展平
  通常情况下通过快照克隆的镜像会保留对父快照的引用，这时候不可以删除该父快照，否则会有影响。如果要删除必须先展平其子镜像，展平的时间取决于镜像的大小.
  从输出可以看出kube/bar_image基于rbd/foo_image@foo_snap。接下来我们使用rbd flatten {pool-name}/{image-name}将kube/bar_image压平：

  #rbd flatten kube/bar_image
  #rbd ls kube -l
  NAME          SIZE PARENT FMT PROT LOCK
  bar_image   10240M          2

- 导入导出RBD image
  RBD image的导出和导入常用于RBD块设备的简单的备份与恢复。
  ``` bash
  #rbd export {pool-name}/{image-name} {file}
  #rbd export rbd/foo_image /tmp/foo_image_export
  ```
  导入RBD image 
  ``` bash
  #rbd import {file} {pool-name}/{image-name}
  #rbd import /tmp/foo_image_export rbd/bar_image --image-format 2

  #rbd ls rbd -l
  NAME                 SIZE PARENT FMT PROT LOCK
  bar_image          10240M          2
  foo_image          10240M          2
  foo_image@foo_snap 10240M          2 yes
  ``` 
---
#### Linux客户端使用
开始之前需要在所需要客户端节点上面安装ceph-common软件包，因为客户端需要调用rbd命令将RBD镜像映射到本地当作一块普通硬盘使用。并还需要把ceph.conf配置文件和授权keyring文件复制到对应的节点。 

- 安装ceph-common软件包  
  #yum install -y ceph-common   

- 创建并授权一个用户可访问指定的rbd存储池
  #ceph auth caps client.osd-mount osd "allow * pool=kvm" mon "allow r"

- 将用户的keyring文件和ceph.conf复制到目标主机的/etc/ceph目录
  
- 修改RBD镜像特性，需要提前创建一个镜像。  
  默认情况下只支持layering和striping特性，需要将其它的特性关闭。
  #rbd feature disable <pool name>/<image name> object-map, fast-diff, deep-flatten

- 执行客户端映射
  ``` bash
  #rbd map --pool <pool name> --image <image name> --keyring /path/to/keyring --user <userType.id>  
  --keyring：指定密钥环文件，如果不指定默认找/etc/ceph/ceph.client.admin.keyring。  
  --user：指定访问的用户   
  #rbd map --pool kvm --image image01 --keyring /etc/ceph ceph.client.osd-mount.keyring --user osd-mount
  ```

- 格式化并挂载。
  ``` bash
  # mkfs.xfs /dev/rbd0
  # mount /dev/rbd0 <mount point>
  ```

- 查看rbd映射信息
  #rbd showmapped

-  空间扩容 
   如果在调整了image的大小，需要在pod运行所在节点执行下面的命令使其对应的镜像生效。
   ``` bash
   # resize2fs /dev/rbd0
   # xfs_growfs /dev/rbd0
   ```

- 断开
  ``` bash
  #umount <mount point>
  #rbd unmap <pool name>/<image name>
  ```
